1. Kindly explain your project architecture?
2. Day to Day activity in office
3. What is the size of data you deal with on daily basis?
4. What is Repartition and Coalesce?
5. What optimisation techniques have you used in your project?
6. What is your role in your project?
7. What is the most challenging problem you have solved in your big data project?
8. Can you explain what happens internally when we submit a Spark job using Spark-Submit?
9. What is a catalyst optimiser?
10. What is the size of your Spark cluster and the configuration of each node?
11. How to tune a spark job? Please explain the techniques we can try.
12. What is Repartition and Coalesce?
13. What is Spark Context vs Spark Session?
14. Role in your current project
15. Difference between dataset & dataframe
16. Difference between broadcast variable & accumulator
17. What is broadcast Join?
18. Types of transformation and difference
19. What are operations of data frames
20. Explain Spark on Yarn Architecture
21. Why reduce is action & reduceByKey transformation
22. What is cache & persist in Spark
23. Difference between RDD & Dataframes
24. What are the challenges you face in spark?
25. How spark is better than Hive?
26. How to enforce schema on a data frame?
27. What is difference between reduceByKey & groupByKey?
28. How do we submit jar files in Spark?
